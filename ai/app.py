# ===============================================
# === IMPORT C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT ===
# ===============================================
import os
import json
import math
import time
import hashlib
from typing import List, Optional, Dict, Any

import numpy as np
import faiss  # Th∆∞ vi·ªán t√¨m ki·∫øm vector c·ªßa Facebook
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field # Th∆∞ vi·ªán ƒë·ªÉ ƒë·ªãnh nghƒ©a API models
from sentence_transformers import SentenceTransformer # Th∆∞ vi·ªán model AI
from dotenv import load_dotenv # Th∆∞ vi·ªán ƒë·ªÉ t·∫£i file .env
from pathlib import Path

# (Gi·∫£ s·ª≠ b·∫°n c√≥ file logger n√†y)
from embedding_logger import logger 

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng (v√≠ d·ª•: PORT) t·ª´ file .env
load_dotenv()

# =================== Config ===================
# C·∫•u h√¨nh cho service
# ===============================================

# T√™n model AI d√πng ƒë·ªÉ t·∫°o embedding
MODEL_NAME = os.getenv("EMBEDDING_MODEL", "AITeamVN/Vietnamese_Embedding_v2")
# C·ªïng (port) m√† service s·∫Ω ch·∫°y
PORT = int(os.getenv("PORT", "8088"))
# Lo·∫°i index FAISS (FLAT = ƒë∆°n gi·∫£n nh·∫•t, HNSW = nhanh h∆°n cho
# d·ªØ li·ªáu l·ªõn)
INDEX_TYPE = os.getenv("INDEX_TYPE", "FLAT").upper()
# Th∆∞ m·ª•c ƒë·ªÉ l∆∞u tr·ªØ c√°c file index
INDEX_DIR = Path(os.getenv("INDEX_DIR", "./index"))
# S·ªë chi·ªÅu c·ªßa vector (model n√†y l√† 1024)
DIM = 1024

# T·∫°o th∆∞ m·ª•c index n·∫øu n√≥ ch∆∞a t·ªìn t·∫°i
INDEX_DIR.mkdir(exist_ok=True)

# =================== FastAPI App ===================
# Kh·ªüi t·∫°o ·ª©ng d·ª•ng web API
# ===============================================
app = FastAPI(
    title="Touring Embedding Service",
    description="Vietnamese semantic search for travel zones & POIs",
    version="2.0"
)

# C·∫•u h√¨nh CORS (Cross-Origin Resource Sharing)
# Cho ph√©p c√°c trang web kh√°c (v√≠ d·ª•: React app) g·ªçi API n√†y
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Cho ph√©p t·∫•t c·∫£
    allow_credentials=True,
    allow_methods=["*"], # Cho ph√©p t·∫•t c·∫£ c√°c ph∆∞∆°ng th·ª©c (GET, POST,...)
    allow_headers=["*"], # Cho ph√©p t·∫•t c·∫£ c√°c header
)

# =================== Load Model ===================
# T·∫£i model AI khi service kh·ªüi ƒë·ªông
# ===============================================
print(f"üì¶ Loading model: {MODEL_NAME}")
t0 = time.time()
# ƒê√¢y l√† l√∫c model AI ƒë∆∞·ª£c t·∫£i v√†o b·ªô nh·ªõ (RAM/VRAM)
model = SentenceTransformer(MODEL_NAME)
print(f"‚úÖ Model loaded in {time.time() - t0:.2f}s")

# =================== FAISS Index ===================
# Kh·ªüi t·∫°o "database" vector (FAISS) v√† metadata
# ===============================================

# 'index' s·∫Ω l∆∞u c√°c vector
index = None 
# 'metadata' s·∫Ω l∆∞u th√¥ng tin ƒëi k√®m (id, text, payload)
metadata = [] 

def load_index():
    """H√†m t·∫£i index v√† metadata t·ª´ file."""
    global index, metadata
    idx_path = INDEX_DIR / "faiss.index" # ƒê∆∞·ªùng d·∫´n file vector
    meta_path = INDEX_DIR / "meta.json"   # ƒê∆∞·ªùng d·∫´n file metadata
    
    # T·∫£i file index (vector)
    if idx_path.exists():
        print(f"üìÇ Loading index from {idx_path}")
        index = faiss.read_index(str(idx_path))
    else:
        # N·∫øu kh√¥ng c√≥ file, t·∫°o index m·ªõi
        print(f"üÜï Creating new {INDEX_TYPE} index")
        if INDEX_TYPE == "HNSW":
            index = faiss.IndexHNSWFlat(DIM, 32)
        else:
            # IndexFlatIP = So kh·ªõp (Inner Product),
            # d√πng cho vector ƒë√£ chu·∫©n h√≥a (normalized)
            index = faiss.IndexFlatIP(DIM)
    
    # T·∫£i file metadata (json)
    if meta_path.exists():
        with open(meta_path, 'r', encoding='utf-8') as f:
            metadata.extend(json.load(f))
    
    print(f"‚úÖ Index ready: {index.ntotal} vectors, {len(metadata)} metadata")

def save_index():
    """H√†m l∆∞u index v√† metadata hi·ªán t·∫°i ra file."""
    # L∆∞u index vector
    faiss.write_index(index, str(INDEX_DIR / "faiss.index"))
    # L∆∞u metadata (d·∫°ng JSON)
    with open(INDEX_DIR / "meta.json", 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"üíæ Saved: {index.ntotal} vectors")

# Ch·∫°y h√†m load_index() ngay khi service kh·ªüi ƒë·ªông
load_index()

# =================== Models ===================
# ƒê·ªãnh nghƒ©a c·∫•u tr√∫c d·ªØ li·ªáu cho c√°c request API
# ===============================================

class EmbedRequest(BaseModel):
    """Input cho /embed"""
    texts: List[str] = Field(..., min_items=1, max_items=100)

class UpsertItem(BaseModel):
    """M·ªôt item (ƒë·ªãa ƒëi·ªÉm) ƒë·ªÉ th√™m v√†o index"""
    id: str
    type: str
    text: str # VƒÉn b·∫£n d√πng ƒë·ªÉ t·∫°o vector
    payload: Optional[Dict[str, Any]] = None # D·ªØ li·ªáu ƒëi k√®m

class UpsertRequest(BaseModel):
    """Input cho /upsert"""
    items: List[UpsertItem]

class SearchRequest(BaseModel):
    """Input cho /search (t√¨m ki·∫øm ƒë∆°n gi·∫£n)"""
    query: str
    top_k: int = Field(10, ge=1, le=100)
    filter_type: Optional[str] = None
    filter_province: Optional[str] = None
    min_score: Optional[float] = 0.0

class HybridSearchRequest(BaseModel):
    """Input cho /hybrid-search (t√¨m ki·∫øm n√¢ng cao)"""
    free_text: Optional[str] = None
    vibes: Optional[List[str]] = None
    avoid: Optional[List[str]] = None
    top_k: int = Field(10, ge=1, le=100)
    filter_type: Optional[str] = None
    filter_province: Optional[str] = None
    boost_vibes: float = Field(1.2, ge=1.0, le=2.0)

# =================== Endpoints ===================
# C√°c API (route) c·ªßa service
# ===============================================

@app.get("/")
def root():
    """Endpoint g·ªëc, cung c·∫•p th√¥ng tin chung."""
    return {
        "service": "Touring Embedding API",
        "version": "2.0",
        "model": MODEL_NAME,
        "endpoints": ["/healthz", "/embed", "/search", "/hybrid-search", "/upsert"]
    }

@app.get("/healthz")
def health():
    """Endpoint ki·ªÉm tra "s·ª©c kh·ªèe" c·ªßa service."""
    return {
        "status": "ok",
        "model": MODEL_NAME,
        "index_type": INDEX_TYPE,
        "vectors": index.ntotal, # S·ªë vector ƒëang c√≥
        "metadata": len(metadata) # S·ªë metadata ƒëang c√≥
    }

@app.get("/stats")
def stats():
    """Endpoint xem th·ªëng k√™ chi ti·∫øt c·ªßa index."""
    return {
        "vectors": index.ntotal,
        "metadata": len(metadata),
        "dimension": DIM,
        "index_type": INDEX_TYPE
    }

@app.post("/embed")
def embed(req: EmbedRequest):
    """Endpoint ƒë·ªÉ bi·∫øn vƒÉn b·∫£n (text) th√†nh vector (embedding)."""
    try:
        # D√πng model AI ƒë·ªÉ m√£ h√≥a vƒÉn b·∫£n
        embeddings = model.encode(
            req.texts,
            normalize_embeddings=True, # R·∫•t quan tr·ªçng cho IndexFlatIP
            show_progress_bar=False,
            convert_to_numpy=True
        )
        return {
            "embeddings": embeddings.tolist(),
            "dimension": embeddings.shape[1],
            "count": len(req.texts)
        }
    except Exception as e:
        raise HTTPException(500, f"Embedding failed: {str(e)}")

@app.post("/upsert")
def upsert(req: UpsertRequest):
    """
    Endpoint th√™m/c·∫≠p nh·∫≠t d·ªØ li·ªáu v√†o index.
    Chi·∫øn l∆∞·ª£c: X√¢y d·ª±ng l·∫°i to√†n b·ªô (Rebuild).
    """
    try:
        global metadata, index
        
        logger.start_operation("Upsert")
        logger.log_upsert_start("http://localhost:8088/upsert", len(req.items))
        
        # --- Step 1: C·∫≠p nh·∫≠t metadata ---
        # T·∫°o 1 set ch·ª©a c√°c ID m·ªõi (ƒë·ªÉ t√¨m ki·∫øm nhanh)
        ids_set = {item.id for item in req.items}
        
        # L·ªçc danh s√°ch metadata c≈©, gi·ªØ l·∫°i nh·ªØng item
        # KH√îNG C√ì ID tr√πng v·ªõi ID m·ªõi
        old_count = len(metadata)
        metadata = [m for m in metadata if m["id"] not in ids_set]
        removed = old_count - len(metadata)
        
        logger.log_metadata_update(removed, len(req.items), old_count, len(metadata))
        
        # --- Step 2: Th√™m item m·ªõi v√†o metadata ---
        new_items = []
        for item in req.items:
            new_items.append({
                "id": item.id,
                "type": item.type,
                "text": item.text,
                "payload": item.payload or {}
            })
        
        metadata.extend(new_items) # Th√™m list item m·ªõi v√†o list metadata
        
        # --- Step 3: X√¢y d·ª±ng l·∫°i (Rebuild) to√†n b·ªô index FAISS ---
        if len(metadata) == 0:
            # N·∫øu kh√¥ng c√≥ metadata, t·∫°o index r·ªóng
            index = faiss.IndexFlatIP(DIM)
            logger.log(" [Upsert] Created empty index")
        else:
            # N·∫øu c√≥ metadata
            # L·∫•y TO√ÄN B·ªò vƒÉn b·∫£n t·ª´ metadata
            all_texts = [m.get("text", "") for m in metadata]
            
            # D√πng model AI t·∫°o l·∫°i embedding cho TO√ÄN B·ªò vƒÉn b·∫£n
            logger.log_embedding_start(len(all_texts))
            embed_start = time.time()
            all_embeddings = model.encode(
                all_texts,
                normalize_embeddings=True,
                show_progress_bar=False,
                convert_to_numpy=True
            )
            embed_duration = time.time() - embed_start
            logger.log_embedding_complete(len(all_texts), embed_duration)
            
            # T·∫°o m·ªôt index FAISS M·ªöI v√† th√™m T·∫§T C·∫¢ embedding v√†o
            index = faiss.IndexFlatIP(DIM)
            index.add(all_embeddings)
            logger.log_index_rebuild(index.ntotal)
        
        # L∆∞u index v√† metadata m·ªõi ra file
        save_index()
        
        logger.log_consistency_check(index.ntotal, len(metadata), index.ntotal == len(metadata))
        logger.end_operation()
        logger.save()
        
        return {
            "ok": True,
            "added": len(req.items), # S·ªë item m·ªõi
            "removed": removed,      # S·ªë item c≈© b·ªã ghi ƒë√®
            "total": index.ntotal  # T·ªïng s·ªë item trong index
        }
    except Exception as e:
        logger.log(f"‚ùå [Upsert] Error: {str(e)}")
        import traceback
        traceback.print_exc()
        logger.save()
        raise HTTPException(500, f"Upsert failed: {str(e)}")

@app.post("/search")
def search(req: SearchRequest):
    """Endpoint t√¨m ki·∫øm ng·ªØ nghƒ©a ƒë∆°n gi·∫£n (1 b∆∞·ªõc)."""
    try:
        if index.ntotal == 0:
            return {"hits": []} # Tr·∫£ v·ªÅ r·ªóng n·∫øu index r·ªóng
        
        search_start = time.time()
        
        # 1. D√πng model AI bi·∫øn query th√†nh vector
        query_emb = model.encode(
            [req.query],
            normalize_embeddings=True,
            show_progress_bar=False,
            convert_to_numpy=True
        )
        
        # 2. T√¨m ki·∫øm trong FAISS
        k = min(req.top_k, index.ntotal)
        scores, indices = index.search(query_emb, k)
        
        # 3. L·ªçc v√† ƒë·ªãnh d·∫°ng k·∫øt qu·∫£
        hits = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(metadata):
                continue
            
            meta = metadata[idx] # L·∫•y metadata d·ª±a tr√™n ch·ªâ s·ªë (idx)
            
            # --- L·ªçc (Post-filtering) ---
            # L·ªçc sau khi t√¨m ki·∫øm
            if req.filter_type and meta["type"] != req.filter_type:
                continue
            if req.filter_province:
                prov = meta.get("payload", {}).get("province", "")
                if prov != req.filter_province:
                    continue
            if req.min_score and score < req.min_score:
                continue
            
            hits.append({
                "id": meta["id"],
                "score": float(score),
                "type": meta["type"],
                "text": meta["text"],
                "payload": meta["payload"]
            })
        
        search_duration = time.time() - search_start
        logger.log_search(req.query, len(hits), search_duration)
        
        return {"hits": hits}
    except Exception as e:
        raise HTTPException(500, f"Search failed: {str(e)}")

@app.post("/hybrid-search")
def hybrid_search(req: HybridSearchRequest):
    """
    T√¨m ki·∫øm hybrid: k·∫øt h·ª£p ng·ªØ nghƒ©a (AI) + tƒÉng ƒëi·ªÉm t·ª´ kh√≥a (keyword boosting)
    (ƒê√¢y l√† logic b·∫°n ƒë√£ h·ªèi)
    """
    try:
        if index.ntotal == 0:
            return {"hits": [], "strategy": "empty_index"}
        
        # === B∆Ø·ªöC 1: T·∫†O QUERY V√Ä L·∫§Y ·ª®NG VI√äN ===
        
        # K·∫øt h·ª£p free_text v√† vibes ƒë·ªÉ t·∫°o th√†nh 1 c√¢u query ng·ªØ nghƒ©a
        query_parts = []
        if req.free_text:
            query_parts.append(req.free_text)
        if req.vibes:
            query_parts.extend(req.vibes)
        
        if not query_parts:
            return {"hits": [], "strategy": "no_query"}
        
        query_text = " ".join(query_parts)
        
        # D√πng model AI ƒë·ªÉ bi·∫øn c√¢u query k·∫øt h·ª£p th√†nh vector
        query_emb = model.encode(
            [query_text],
            normalize_embeddings=True,
            show_progress_bar=False,
            convert_to_numpy=True
        )
        
        # L·∫•y m·ªôt s·ªë l∆∞·ª£ng ·ª©ng vi√™n l·ªõn h∆°n m·ª©c c·∫ßn thi·∫øt (v√≠ d·ª•: top_k=10 th√¨ l·∫•y 30)
        k = min(req.top_k * 3, index.ntotal)
        scores, indices = index.search(query_emb, k)
        
        # === B∆Ø·ªöC 2: S√ÄNG L·ªåC V√Ä CH·∫§M ƒêI·ªÇM L·∫†I (RE-RANKING) ===
        
        hits = [] # Danh s√°ch k·∫øt qu·∫£ cu·ªëi c√πng
        
        # Chu·∫©n b·ªã danh s√°ch t·ª´ kh√≥a (vi·∫øt th∆∞·ªùng) ƒë·ªÉ so s√°nh
        vibes_lower = [v.lower() for v in (req.vibes or [])]
        avoid_lower = [a.lower() for a in (req.avoid or [])]
        
        # B·∫Øt ƒë·∫ßu duy·ªát qua t·ª´ng ·ª©ng vi√™n
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0 or idx >= len(metadata):
                continue
            
            meta = metadata[idx]
            text_lower = meta["text"].lower()
            
            # --- L·ªåC B·ªé (AVOID) ---
            if avoid_lower and any(av in text_lower for av in avoid_lower):
                continue 
            
            # --- L·ªåC C·ª®NG (FILTER) ---
            if req.filter_type and meta["type"] != req.filter_type:
                continue
            if req.filter_province:
                prov = meta.get("payload", {}).get("province", "")
                if prov != req.filter_province:
                    continue
            
            # --- TƒÇNG ƒêI·ªÇM (BOOST VIBES) ---
            adjusted_score = float(score)
            vibe_matches = sum(1 for v in vibes_lower if v in text_lower)
            
            if vibe_matches > 0:
                adjusted_score *= (req.boost_vibes ** vibe_matches)
            
            # Th√™m v√†o danh s√°ch k·∫øt qu·∫£ v·ªõi ƒëi·ªÉm M·ªöI
            hits.append({
                "id": meta["id"],
                "score": adjusted_score,
                "original_score": float(score),
                "vibe_matches": vibe_matches,
                "type": meta["type"],
                "text": meta["text"],
                "payload": meta["payload"]
            })
        
        # === B∆Ø·ªöC 3: S·∫ÆP X·∫æP V√Ä TR·∫¢ V·ªÄ ===
        
        # S·∫Øp x·∫øp l·∫°i 'hits' d·ª±a tr√™n ƒëi·ªÉm M·ªöI (score) t·ª´ cao ƒë·∫øn th·∫•p
        hits.sort(key=lambda x: x["score"], reverse=True)
        
        # C·∫Øt l·∫•y top_k (v√≠ d·ª•: 10) k·∫øt qu·∫£ t·ªët nh·∫•t
        hits = hits[:req.top_k]
        
        return {
            "hits": hits,
            "strategy": "hybrid",
            "query_text": query_text,
            "total_candidates": len(hits)
        }
    except Exception as e:
        raise HTTPException(500, f"Hybrid search failed: {str(e)}")

@app.post("/reset")
def reset():
    """Endpoint x√≥a s·∫°ch index (h·ªØu √≠ch khi test)."""
    global index, metadata
    
    # T·∫°o l·∫°i index v√† metadata r·ªóng
    if INDEX_TYPE == "HNSW":
        index = faiss.IndexHNSWFlat(DIM, 32)
    else:
        index = faiss.IndexFlatIP(DIM)
    metadata = []
    
    # L∆∞u tr·∫°ng th√°i r·ªóng ra file
    save_index()
    return {"ok": True, "message": "Index reset"}

# =================== Run App ===================
# ƒêo·∫°n n√†y ch·ªâ ch·∫°y khi b·∫°n ch·∫°y file Python tr·ª±c ti·∫øp
# ===============================================
if __name__ == "__main__":
    import uvicorn
    # Ch·∫°y service API b·∫±ng uvicorn tr√™n c·ªïng (PORT) ƒë√£ ƒë·ªãnh nghƒ©a
    uvicorn.run(app, host="0.0.0.0", port=PORT)